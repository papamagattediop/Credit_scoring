{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91748125",
   "metadata": {},
   "source": [
    "<div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 40px; border-radius: 15px;'>\n",
    "    <h1 style='color: white; text-align: center; font-size: 48px; margin: 0; font-weight: 800;'>MODELISATION FINALE</h1>\n",
    "    <h2 style='color: #e0e7ff; text-align: center; font-size: 28px; margin-top: 15px;'>Comparaison et Selection du Champion</h2>\n",
    "    <p style='color: white; text-align: center; font-size: 16px; margin-top: 20px;'>Projet CLF02 - Phase 4 Finale</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610faf55",
   "metadata": {},
   "source": [
    "<div class='section-header'>\n",
    "    <h2 style='margin: 0;'>1. CONFIGURATION</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf643fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import json\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import mutual_info_classif, f_classif\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, f1_score, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "\n",
    "import lightgbm as lgb\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.lightgbm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "N_FOLDS = 5\n",
    "N_FEATURES_SELECTED = 150\n",
    "\n",
    "print('Configuration terminee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4a8138",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri('file:../mlruns')\n",
    "mlflow.set_experiment('credit_scoring_final')\n",
    "print('MLflow configure')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86bd0b8",
   "metadata": {},
   "source": [
    "<div class='section-header'>\n",
    "    <h2 style='margin: 0;'>2. CHARGEMENT DES DONNEES</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c693ef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('../data/processed')\n",
    "\n",
    "print('Chargement des donnees...')\n",
    "train = pd.read_csv(DATA_PATH / 'train_final.csv')\n",
    "test = pd.read_csv(DATA_PATH / 'test_final.csv')\n",
    "\n",
    "X = train.drop('TARGET', axis=1)\n",
    "y = train['TARGET']\n",
    "X_test = test.copy()\n",
    "\n",
    "print(f'Train: {train.shape}')\n",
    "print(f'X: {X.shape}')\n",
    "print(f'Distribution classe 1: {y.mean()*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97b15f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer colonnes numeriques\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "non_numeric = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "if len(non_numeric) > 0:\n",
    "    print(f'Colonnes non-numeriques: {len(non_numeric)}')\n",
    "    X = X[numeric_cols]\n",
    "    X_test = X_test[numeric_cols]\n",
    "\n",
    "print(f'Donnees filtrees: {X.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc58ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split stratifie\n",
    "X_temp, X_test_final, y_temp, y_test_final = train_test_split(\n",
    "    X, y, test_size=0.15, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.176, stratify=y_temp, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print('Split des donnees:')\n",
    "print(f'  Train: {X_train.shape}')\n",
    "print(f'  Validation: {X_val.shape}')\n",
    "print(f'  Test: {X_test_final.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e39dba",
   "metadata": {},
   "source": [
    "<div class='section-header'>\n",
    "    <h2 style='margin: 0;'>3. FONCTIONS UTILITAIRES</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edf1fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_business_cost(y_true, y_pred_proba, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calcule le business cost avec ratio automatique\n",
    "    \"\"\"\n",
    "    # Calculer le ratio automatiquement\n",
    "    n_positive = np.sum(y_true == 1)\n",
    "    n_negative = np.sum(y_true == 0)\n",
    "    ratio = n_negative / n_positive if n_positive > 0 else 1\n",
    "    \n",
    "    # Définir les coûts (seules les erreurs coûtent)\n",
    "    cost_fn = 1.0\n",
    "    cost_fp = 1.0 / ratio\n",
    "    \n",
    "    # Prédictions et matrice de confusion\n",
    "    y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    \n",
    "    # Coût total (seulement FN et FP)\n",
    "    total_cost = -(fn * cost_fn) - (fp * cost_fp)\n",
    "    \n",
    "    return total_cost, {'TP': tp, 'TN': tn, 'FP': fp, 'FN': fn}\n",
    "\n",
    "def evaluate_model(y_true, y_pred_proba, threshold=0.5):\n",
    "    y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "    auc = roc_auc_score(y_true, y_pred_proba)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    business_cost, cm_dict = calculate_business_cost(y_true, y_pred_proba, threshold)\n",
    "    return {'auc': auc, 'precision': precision, 'recall': recall, 'f1': f1, 'business_cost': business_cost, 'threshold': threshold, **cm_dict}\n",
    "\n",
    "print('Fonctions definies')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39156bf5",
   "metadata": {},
   "source": [
    "<div class='section-header'>\n",
    "    <h2 style='margin: 0;'>4. FEATURE SELECTION</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e229fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Feature selection multi-methodes...')\n",
    "\n",
    "# Mutual Information\n",
    "mi_scores = mutual_info_classif(X_train, y_train, random_state=RANDOM_STATE)\n",
    "mi_features = X_train.columns[np.argsort(mi_scores)[-N_FEATURES_SELECTED:]].tolist()\n",
    "print(f'1. Mutual Information: {len(mi_features)} features')\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_features = X_train.columns[np.argsort(rf.feature_importances_)[-N_FEATURES_SELECTED:]].tolist()\n",
    "print(f'2. Random Forest: {len(rf_features)} features')\n",
    "\n",
    "# F-score\n",
    "f_scores, _ = f_classif(X_train, y_train)\n",
    "f_features = X_train.columns[np.argsort(f_scores)[-N_FEATURES_SELECTED:]].tolist()\n",
    "print(f'3. F-score: {len(f_features)} features')\n",
    "\n",
    "# Intersection\n",
    "all_features = mi_features + rf_features + f_features\n",
    "feature_counts = Counter(all_features)\n",
    "selected_features = [f for f, count in feature_counts.items() if count >= 2]\n",
    "\n",
    "if len(selected_features) < N_FEATURES_SELECTED:\n",
    "    for feat in mi_features:\n",
    "        if feat not in selected_features:\n",
    "            selected_features.append(feat)\n",
    "            if len(selected_features) == N_FEATURES_SELECTED:\n",
    "                break\n",
    "\n",
    "selected_features = selected_features[:N_FEATURES_SELECTED]\n",
    "print(f'\\nFeatures selectionnees: {len(selected_features)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee13440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer selection\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_val_selected = X_val[selected_features]\n",
    "X_test_selected = X_test_final[selected_features]\n",
    "\n",
    "print(f'Shapes apres selection:')\n",
    "print(f'  Train: {X_train_selected.shape}')\n",
    "print(f'  Val: {X_val_selected.shape}')\n",
    "print(f'  Test: {X_test_selected.shape}')\n",
    "\n",
    "# Sauvegarder\n",
    "FEATURES_PATH = Path('../artifacts/final_model')\n",
    "FEATURES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "joblib.dump(selected_features, FEATURES_PATH / 'selected_features.pkl')\n",
    "print(f'Features sauvegardees')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8576170",
   "metadata": {},
   "source": [
    "<div class='section-header'>\n",
    "    <h2 style='margin: 0;'>5. BASELINE COMPARISON</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b32a2b1",
   "metadata": {},
   "source": [
    "### 5.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c483bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Logistic Regression Baseline')\n",
    "scaler_lr = StandardScaler()\n",
    "X_train_scaled = scaler_lr.fit_transform(X_train_selected)\n",
    "X_val_scaled = scaler_lr.transform(X_val_selected)\n",
    "\n",
    "logreg = LogisticRegression(class_weight='balanced', C=1.0, max_iter=1000, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_val_lr = logreg.predict_proba(X_val_scaled)[:, 1]\n",
    "metrics_val_lr = evaluate_model(y_val, y_pred_val_lr)\n",
    "\n",
    "print(f\"AUC: {metrics_val_lr['auc']:.4f}\")\n",
    "print(f\"F1: {metrics_val_lr['f1']:.4f}\")\n",
    "print(f\"Cout: {metrics_val_lr['business_cost']:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b99d20",
   "metadata": {},
   "source": [
    "### 5.2 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b2a6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('LightGBM Baseline')\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "\n",
    "lgbm = lgb.LGBMClassifier(\n",
    "    objective='binary', metric='auc', scale_pos_weight=scale_pos_weight,\n",
    "    n_estimators=200, learning_rate=0.05, num_leaves=31, max_depth=7,\n",
    "    random_state=RANDOM_STATE, n_jobs=-1, verbose=-1\n",
    ")\n",
    "lgbm.fit(X_train_selected, y_train)\n",
    "\n",
    "y_pred_val_lgbm = lgbm.predict_proba(X_val_selected)[:, 1]\n",
    "metrics_val_lgbm = evaluate_model(y_val, y_pred_val_lgbm)\n",
    "\n",
    "print(f\"AUC: {metrics_val_lgbm['auc']:.4f}\")\n",
    "print(f\"F1: {metrics_val_lgbm['f1']:.4f}\")\n",
    "print(f\"Cout: {metrics_val_lgbm['business_cost']:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cc2816",
   "metadata": {},
   "source": [
    "### 5.3 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f234b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random Forest Baseline')\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200, max_depth=15, min_samples_split=20, min_samples_leaf=10,\n",
    "    max_features='sqrt', class_weight='balanced', random_state=RANDOM_STATE, n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train_selected, y_train)\n",
    "\n",
    "y_pred_val_rf = rf.predict_proba(X_val_selected)[:, 1]\n",
    "metrics_val_rf = evaluate_model(y_val, y_pred_val_rf)\n",
    "\n",
    "print(f\"AUC: {metrics_val_rf['auc']:.4f}\")\n",
    "print(f\"F1: {metrics_val_rf['f1']:.4f}\")\n",
    "print(f\"Cout: {metrics_val_rf['business_cost']:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa916101",
   "metadata": {},
   "source": [
    "<div class='section-header'>\n",
    "    <h2 style='margin: 0;'>6. COMPARAISON MULTI-CRITERES</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eb6381",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = [\n",
    "    {'model': 'Logistic Regression', 'auc': metrics_val_lr['auc'], 'f1': metrics_val_lr['f1'], 'business_cost': metrics_val_lr['business_cost']},\n",
    "    {'model': 'LightGBM', 'auc': metrics_val_lgbm['auc'], 'f1': metrics_val_lgbm['f1'], 'business_cost': metrics_val_lgbm['business_cost']},\n",
    "    {'model': 'Random Forest', 'auc': metrics_val_rf['auc'], 'f1': metrics_val_rf['f1'], 'business_cost': metrics_val_rf['business_cost']}\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(baseline_results)\n",
    "df['auc_norm'] = df['auc']\n",
    "df['cost_norm'] = 1 - (df['business_cost'] - df['business_cost'].min()) / (df['business_cost'].max() - df['business_cost'].min() + 1e-10)\n",
    "df['f1_norm'] = df['f1']\n",
    "df['final_score'] = 0.40 * df['auc_norm'] + 0.40 * df['cost_norm'] + 0.20 * df['f1_norm']\n",
    "df = df.sort_values('final_score', ascending=False)\n",
    "\n",
    "print('Comparaison (40% AUC + 40% Cout + 20% F1):')\n",
    "print(df[['model', 'auc', 'f1', 'business_cost', 'final_score']].to_string(index=False))\n",
    "\n",
    "champion_name = df.iloc[0]['model']\n",
    "print(f'\\nChampion: {champion_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e8ec72",
   "metadata": {},
   "source": [
    "<div class='section-header'>\n",
    "    <h2 style='margin: 0;'>7. OPTIMISATION DU CHAMPION</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a1fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selectionner champion\n",
    "if champion_name == 'LightGBM':\n",
    "    champion_model = lgbm\n",
    "    X_train_champion = X_train_selected\n",
    "    X_val_champion = X_val_selected\n",
    "    X_test_champion = X_test_selected\n",
    "    needs_scaling = False\n",
    "elif champion_name == 'Logistic Regression':\n",
    "    champion_model = logreg\n",
    "    X_train_champion = X_train_scaled\n",
    "    X_val_champion = X_val_scaled\n",
    "    X_test_champion = scaler_lr.transform(X_test_selected)\n",
    "    needs_scaling = True\n",
    "else:\n",
    "    champion_model = rf\n",
    "    X_train_champion = X_train_selected\n",
    "    X_val_champion = X_val_selected\n",
    "    X_test_champion = X_test_selected\n",
    "    needs_scaling = False\n",
    "\n",
    "print(f'Champion: {champion_name}')\n",
    "print(f'Scaling: {needs_scaling}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2306311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Optimisation hyperparametres...')\n",
    "\n",
    "if champion_name == 'LightGBM':\n",
    "    param_distributions = {\n",
    "        'n_estimators': [100, 200, 300, 500],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'max_depth': [5, 7, 10, 15],\n",
    "        'num_leaves': [31, 63, 127],\n",
    "        'min_child_samples': [10, 20, 30],\n",
    "        'subsample': [0.7, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.7, 0.8, 1.0]\n",
    "    }\n",
    "    base_model = lgb.LGBMClassifier(objective='binary', metric='auc', scale_pos_weight=scale_pos_weight, random_state=RANDOM_STATE, n_jobs=-1, verbose=-1)\n",
    "    n_iter = 50\n",
    "elif champion_name == 'Logistic Regression':\n",
    "    param_distributions = {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear', 'saga'],\n",
    "        'class_weight': ['balanced', None]\n",
    "    }\n",
    "    base_model = LogisticRegression(random_state=RANDOM_STATE, n_jobs=-1, max_iter=2000)\n",
    "    n_iter = 30\n",
    "else:\n",
    "    param_distributions = {\n",
    "        'n_estimators': [100, 200, 300, 500],\n",
    "        'max_depth': [10, 15, 20, 25],\n",
    "        'min_samples_split': [2, 5, 10, 20],\n",
    "        'min_samples_leaf': [1, 2, 5, 10],\n",
    "        'max_features': ['sqrt', 'log2']\n",
    "    }\n",
    "    base_model = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1, class_weight='balanced')\n",
    "    n_iter = 40\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    base_model, param_distributions, n_iter=n_iter,\n",
    "    cv=StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE),\n",
    "    scoring='roc_auc', n_jobs=-1, verbose=1, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "random_search.fit(X_train_champion, y_train)\n",
    "print(f'\\nOptimisation terminee')\n",
    "print(f'Meilleur score CV: {random_search.best_score_:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bab623",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = random_search.best_estimator_\n",
    "y_pred_val_opt = best_model.predict_proba(X_val_champion)[:, 1]\n",
    "metrics_val_opt = evaluate_model(y_val, y_pred_val_opt)\n",
    "\n",
    "print('Resultats apres optimisation:')\n",
    "print(f\"  AUC: {metrics_val_opt['auc']:.4f}\")\n",
    "print(f\"  F1: {metrics_val_opt['f1']:.4f}\")\n",
    "print(f\"  Cout: {metrics_val_opt['business_cost']:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160f9536",
   "metadata": {},
   "source": [
    "<div class='section-header'>\n",
    "    <h2 style='margin: 0;'>8. THRESHOLD TUNING</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06396cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Optimisation threshold...')\n",
    "thresholds = np.arange(0.3, 0.8, 0.02)\n",
    "threshold_results = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    metrics = evaluate_model(y_val, y_pred_val_opt, threshold=threshold)\n",
    "    threshold_results.append(metrics)\n",
    "\n",
    "threshold_df = pd.DataFrame(threshold_results)\n",
    "best_threshold_idx = threshold_df['business_cost'].idxmax()\n",
    "best_threshold = threshold_df.loc[best_threshold_idx, 'threshold']\n",
    "\n",
    "print(f'Threshold optimal: {best_threshold:.3f}')\n",
    "print(f\"Cout optimal: {threshold_df.loc[best_threshold_idx, 'business_cost']:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2356cf3c",
   "metadata": {},
   "source": [
    "<div class='section-header'>\n",
    "    <h2 style='margin: 0;'>9. VALIDATION FINALE</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b97f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = best_model.predict_proba(X_test_champion)[:, 1]\n",
    "metrics_test = evaluate_model(y_test_final, y_pred_test, threshold=best_threshold)\n",
    "\n",
    "print('VALIDATION FINALE - TEST SET')\n",
    "print(f\"  AUC: {metrics_test['auc']:.4f}\")\n",
    "print(f\"  Precision: {metrics_test['precision']:.4f}\")\n",
    "print(f\"  Recall: {metrics_test['recall']:.4f}\")\n",
    "print(f\"  F1: {metrics_test['f1']:.4f}\")\n",
    "print(f\"  Cout: {metrics_test['business_cost']:.0f}\")\n",
    "print(f\"  Threshold: {best_threshold:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e004912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test_final, y_pred_test)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, linewidth=2, label=f\"{champion_name} (AUC = {metrics_test['auc']:.4f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random')\n",
    "plt.xlabel('False Positive Rate', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('True Positive Rate', fontsize=12, fontweight='bold')\n",
    "plt.title('ROC Curve - Test Set', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa2d36a",
   "metadata": {},
   "source": [
    "<div class='section-header'>\n",
    "    <h2 style='margin: 0;'>10. SAUVEGARDE</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940eb66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_PATH = Path('../artifacts/final_model')\n",
    "FINAL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Sauvegarde du modele final...')\n",
    "\n",
    "joblib.dump(best_model, FINAL_PATH / 'best_model.pkl')\n",
    "\n",
    "if needs_scaling:\n",
    "    joblib.dump(scaler_lr, FINAL_PATH / 'scaler.pkl')\n",
    "\n",
    "with open(FINAL_PATH / 'best_threshold.json', 'w') as f:\n",
    "    json.dump({'threshold': float(best_threshold)}, f, indent=4)\n",
    "\n",
    "performance = {\n",
    "    'model_name': champion_name,\n",
    "    'best_params': random_search.best_params_,\n",
    "    'test_metrics': {\n",
    "        'auc': float(metrics_test['auc']),\n",
    "        'precision': float(metrics_test['precision']),\n",
    "        'recall': float(metrics_test['recall']),\n",
    "        'f1': float(metrics_test['f1']),\n",
    "        'business_cost': float(metrics_test['business_cost'])\n",
    "    },\n",
    "    'timestamp': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "with open(FINAL_PATH / 'performance_metrics.json', 'w') as f:\n",
    "    json.dump(performance, f, indent=4)\n",
    "\n",
    "print(f'Sauvegarde terminee dans {FINAL_PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0802574",
   "metadata": {},
   "source": [
    "<div class='section-header'>\n",
    "    <h2 style='margin: 0;'>11. RESUME FINAL</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063b0799",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RESUME FINAL')\n",
    "print('='*60)\n",
    "print(f'Modele champion: {champion_name}')\n",
    "print(f'\\nPerformances Test Set:')\n",
    "print(f\"  AUC:       {metrics_test['auc']:.4f}\")\n",
    "print(f\"  Precision: {metrics_test['precision']:.4f}\")\n",
    "print(f\"  Recall:    {metrics_test['recall']:.4f}\")\n",
    "print(f\"  F1:        {metrics_test['f1']:.4f}\")\n",
    "print(f\"  Cout:      {metrics_test['business_cost']:.0f}\")\n",
    "print(f'\\nConfiguration:')\n",
    "print(f'  Features:  {N_FEATURES_SELECTED}')\n",
    "print(f'  Threshold: {best_threshold:.3f}')\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f6df56",
   "metadata": {},
   "source": [
    "<div style='background: linear-gradient(135deg, #10b981 0%, #059669 100%); padding: 30px; border-radius: 10px; margin-top: 30px;'>\n",
    "    <h2 style='color: white; text-align: center; margin: 0;'>MODELISATION FINALE TERMINEE</h2>\n",
    "    <p style='color: white; text-align: center; margin-top: 15px;'>Le modele champion est pret pour la production</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
